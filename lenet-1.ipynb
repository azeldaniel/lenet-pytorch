{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitresearchconda6e46ab89dee4447294274d22b6e2b99b",
   "display_name": "Python 3.8.5 64-bit ('research': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# LeNet-1 PyTorch Implementation\n",
    "\n",
    "In this notebook, we implement Yann LeCun's LeNet-1 convolutional neural network with the PyTorch library. We will train and assess the developed model with the MNIST digit classification dataset. LeNet-1 was a small CNN, which merely included five layers. The network was developed to accommodate minute, single-channel images of size (28×28)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "First we import the necessary libraries that we will use."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "## LeNet-1 Implementation in PyTorch\n",
    "\n",
    "LeNet-1 only contains only five layers, and they are:\n",
    "\n",
    "1. Layer C1: Convolution Layer (4, 5×5)\n",
    "2. Layer S2: Pooling Layer (2×2)\n",
    "3. Layer C3: Convolution Layer (12, 5×5)\n",
    "4. Layer S4: Pooling Layer (2×2)\n",
    "5. Layer F5: Fully Connected Layer (10)\n",
    "\n",
    "We can define these layers in a class called `LeNet1` as shown below.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet1(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The LeNet-1 module.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # Mandatory call to super class module.\n",
    "        super(LeNet1, self).__init__()\n",
    "\n",
    "        # Defining the feature extraction layers.\n",
    "        self.feature_extractor = torch.nn.Sequential(\n",
    "\n",
    "            # Layer 1 - Conv2d(4, 5x5) - Nx1x28x28 -> Nx4x24x24\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=4, kernel_size=5),\n",
    "            torch.nn.Tanh(),\n",
    "\n",
    "            # Layer 2 - AvgPool2d(2x2) - Nx4x24x24 -> Nx4x12x12\n",
    "            torch.nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Layer 3 - Conv2d(12, 5x5) - Nx4x12x12 -> Nx12x8x8\n",
    "            torch.nn.Conv2d(in_channels=4, out_channels=12, kernel_size=5),\n",
    "            torch.nn.Tanh(),\n",
    "\n",
    "            # Layer 4 - AvgPool2d(2x2) - Nx12x8x8 -> Nx12x4x4\n",
    "            torch.nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # Defining the classification layers.\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "\n",
    "            # Layer 5 - FullyConnected(10) - Nx1x192 -> Nx1x10\n",
    "            torch.nn.Linear(in_features=12*4*4, out_features=10),\n",
    "            torch.nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Forward pass through the feature extractor - Nx1x28x28 -> Nx12x4x4\n",
    "        x = self.feature_extractor(x)\n",
    "\n",
    "        # Flattening the feature map - Nx12x4x4 -> Nx1x192\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # Forward pass through the classifier - Nx1x192 -> Nx1x10\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Note that a `forward` function was also defined. This function dictates how to forward-propagate the input through the network. "
   ]
  },
  {
   "source": [
    "## Loading the MNIST dataset\n",
    "\n",
    "Next we load the MNIST digit classification dataset. Luckily, PyTorch has a nifty solution that allows us to easily download the dataset and use it. This solution is shown below.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a transform for the images.\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.Resize((28,28)), torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0,), (1,))]\n",
    ")\n",
    "\n",
    "# Loading the training and validation data.\n",
    "train_set = torchvision.datasets.MNIST(root='./mnist', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True, num_workers=2)\n",
    "#val_loader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "# Loading the testing data.\n",
    "test_set = torchvision.datasets.MNIST(root='./mnist', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=4, shuffle=False, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(test_set, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "# Defining the classes [0, ..., 9].\n",
    "classes = [x for x in range(10)]"
   ]
  },
  {
   "source": [
    "### Showing Sample Images\n",
    "\n",
    "To confirm that the data was loaded correctly, we design a function below to show some sample images from the dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    npimg = image.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "def show_sample_images():\n",
    "\n",
    "    # get some random training images\n",
    "    dataiter = iter(train_loader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    # Showing the image(s).\n",
    "    show_image(torchvision.utils.make_grid(images))\n",
    "\n",
    "    # Printing the labels.\n",
    "    print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "show_sample_images()"
   ]
  },
  {
   "source": [
    "## Using the model\n",
    "\n",
    "Before we proceed, we check to see your the machine has a GPU installed. If so, we use the GPU for training, else, we use the CPU."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LeNet1().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "source": [
    "## Training the model\n",
    "\n",
    "We devise a function below to train the model. We use regular Stochastic Gradient Descent and Mean Squared Error loss for training as defined by LeCun."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, optimizer, epochs):\n",
    "\n",
    "    # Iterate for several epochs\n",
    "    for epoch in tqdm.notebook.trange(epochs):\n",
    "        train_loss = val_loss = 0.0\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            \n",
    "            if phase == 'train':\n",
    "                loader = train_loader\n",
    "                model.train(True)\n",
    "            else:\n",
    "                loader = val_loader\n",
    "                model.train(False)\n",
    "\n",
    "            # Iterate for each data item in the training set\n",
    "            for i, data in enumerate(loader, 0):\n",
    "                \n",
    "                # Get the sample input data.\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "                # Reset the gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Perform forward pass.\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Calculate current model loss.\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                     \n",
    "                     # Perform backward pass.\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    train_loss += loss.item()\n",
    "                else:\n",
    "                    val_loss += loss.item()\n",
    "        \n",
    "        print('Epoch %d - Train Loss: %.3f Validation Loss %.3f' % (epoch + 1, train_loss/len(train_loader), val_loss/len(val_loader)))\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "train(model, train_loader, val_loader, optimizer, 20)"
   ]
  },
  {
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "We evaluate the model on a ransom sample of test data to see how well it performs."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "\n",
    "    dataiter = iter(test_loader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    # Showing the test images\n",
    "    show_image(torchvision.utils.make_grid(images))\n",
    "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "    outputs = model(images.to(device))\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n",
    "\n",
    "test(model, test_loader)"
   ]
  },
  {
   "source": [
    "### Evaluating on the entire dataset\n",
    "\n",
    "We further evaluate the model's performance on the entire dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_full(model, test_loader):\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "test_full(model, test_loader)"
   ]
  },
  {
   "source": [
    "### Evaluating class by class\n",
    "\n",
    "We further evaluate the class by class accuracy of the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_class(model, test_loader):\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images.to(device))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "test_class(model, test_loader)"
   ]
  }
 ]
}